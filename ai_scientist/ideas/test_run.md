# The Impact of Learning Rate on MNIST Training Stability

## Title

The Impact of Learning Rate on MNIST Training Stability

## Keywords

Deep Learning, Optimization, Hyperparameters, Stability, MNIST

## TL;DR

Investigating how extreme learning rates affect the convergence and stability of training a simple MLP on MNIST.

## Abstract

This study aims to empirically analyze the effect of varying learning rates on the training dynamics of a Multi-Layer Perceptron (MLP) trained on the MNIST dataset. We hypothesize that there exists a critical threshold beyond which training becomes unstable or diverges. By systematically sweeping learning rates and observing loss landscapes and accuracy metrics, we seek to characterize the relationship between learning rate magnitude and optimization stability.
